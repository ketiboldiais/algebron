import MdxLayout from "@/components/mdx-layout";
import {
    UnitSquare, 
    EventDiagram,
} from "@/components/Fig";

# Probability

<TOC>

- [Terminology](#terminology)
- [Probability Axioms](#probability-axioms)
- [Discrete Uniform Law](#discrete-uniform-law)
- [Probability Calculation Steps](#probability-calculation-steps)
- [Countable Additivity](#countable-additivity)
- [Conditional Probabilities](#conditional-probabilities)
  - [Multiplication Rule](#multiplication-rule)
- [Total Probability Theorem](#total-probability-theorem)
- [Bayes's Rule](#bayess-rule)
- [Independence](#independence)

</TOC>




## Terminology
- An _experiment_ is a sequence of operations carried out under specified conditions.
- The result of an experiment is called an _outcome_.     
- If an experiment's outcomes are not predetermined, then the experiment is called a _chance_ experiment. 
- __*definition*__. The _sample space_, denoted ${\Omega,}$ is the set of all possible outcomes of a statistical experiment. Each outcome in a sample space is called a _sample point_. 
- __*definition*__. A _probability model_ is a sample space and an operation of assigning probabilities.
- __*example*__. When we toss a coin, we have a sample space with two outcomes:

    $$
        \Omega = \set{H, T}.
    $$

    where ${H}$ is _heads_ and ${T}$ is _tails_.  
- __*example*__. If we toss the coin three times, then the sample space is:
    $$
        
        \Omega = \left\lbrace \begin{matrix}
            HHH & HHT \\ 
            HTH & THH \\ 
            HTT & TTH \\ 
            THT & TTT
        \end{matrix} \right\rbrace.
    $$
- The sample space resulting from tossing a coin finitely many times is an example of a _discrete_ and _finite_ sample space.
- __*example*__. A bullet is shot at the square target below.

    <UnitSquare/>

    The sample space of the bullet hitting the target is the set 

    $$
        \set{(x,y) : 0 \leq x,y \leq 1}.
    $$

    This is an example of a _continuous_ and _infinite_ sample space, since there are infinitely many pairs ${(x,y)}$ with ${0 \leq x,y \leq 1.}$
- Probabilities are assigned to _events_. 
- __*definition*__. An _event_ is a subset of the sample space. 
  - __*example*__. Below is a sample space, with events ${A}$ and ${B.}$
    <EventDiagram/>

import { L016B } from "@/components/Fig"; 

## Probability Axioms
- By convention, a probability value is always between ${0}$ and ${1.}$
- __*axiom*__. A probability of some event ${A,}$ denoted ${P(A),}$ is a nonnegative real number. That is, ${P(A) \geq 0.}$
  - This is called the _Nonnegativity Axiom_ of Probability Theory.
- __*axiom*__. The probability of a sample space is ${1.}$ That is, ${P(\Omega) = 1.}$
  - This is called the _Normalization Axiom_ of Probability Theory.
- With just the two axioms, we have the following corollaries:
    1. __*corollary*__. Given an event ${A,}$ we have ${P(A) \leq 1.}$
    2. __*corollary*__. ${P(\varnothing) = 0.}$
- __*axiom*__. Given events ${A}$ and ${B,}$ if ${A \cap B = \varnothing,}$ then ${P(A \cup B) = P(A) + P(B).}$
  - This is called the _Finite Additivity Axiom_ of Probability Theory. 
  - We will state a stronger version of this axiom in later sections.
- From the three axioms, we can derive several corollaries.
  - __*corollary*__. ${P(A) + P(A^c) = 1.}$
  - __*corollary*__.
    $$
    \begin{aligned}
        P(\set{s_1, s_2, \ldots, s_k}) &= P(\set{s_1}) + \ldots + P(\set{s_k}) \\[1em]
        &= P(s_1) + \ldots + P(s_2).
    \end{aligned}
    $$
  - __*corollary*__. If ${A \subset B,}$ then ${P(A) \leq P(B).}$ That is, if we have a set ${A}$ that's smaller than a set ${B,}$ then the probability that an outcome falls inside ${B}$ is at least as big as the probability that an outcome falls inside ${A.}$  
  - __*corollary*__. ${P(A \cup B) = P(A) + P(B) - P(A \cap B).}$
    <L016B/>
  - __*corollary*__. ${P(A \cup B) \leq P(A) - P(B).}$
    - This is called the _union bound inequality_.
  - __*corollary*__. ${P(A \cup B \cup C) = P(A) + P(A^c \cap B) + P(A^c \cap B^c \cap C).}$

## Discrete Uniform Law
- __*definition*__. A probability model obeys the _discrete uniform law_ if it satisfies the following conditions:
  1. The sample space ${\Omega}$ is _finite_.
  2. The sample space ${\Omega}$ comprises ${n}$ elements, each equally likely. That is, each element has probability ${1/n.}$
  3. If an event ${A \subset \Omega}$ consists of ${k}$ elements, then
      $$
          P(A) = k \cdot \dfrac{1}{n} = \dfrac{k}{n}.
      $$

## Probability Calculation Steps
1. Specify the sample space.
2. Specify a probability law.
3. Identify the event of interest.
4. Calculate the probability of that event. 

## Countable Additivity
- Consider an experiment where we toss a coin. We count how many times we had to toss until we reach first reach heads. The first heads might appear in the first toss, the second toss, the third, fourth, etc. Thus, our sample space is the set of positive integers:
  $$
    \Omega = \set{1,2,3,\ldots} = \Z^+.
  $$ 
- This is an example of a _discrete_ but _infinite_ sample space.
- Now let's determine what probability law applies. We will discuss this law later, but for now, assume that the probability law is:
  $$
    P(n) = \dfrac{1}{2^n}.
  $$ 
  where ${n}$ is the number of tosses until the first heads.
  - Let's verify that this probability law, as applied, makes sense. 
  - The probabilities must sum to ${1:}$
    $$
      \begin{aligned}
      \sum_{n = 1}^{\infty} \dfrac{1}{2^n} &= \dfrac{1}{2} \sum_{n = 0}^{\infty} \dfrac{1}{2^n} \\[2em]
      &= \dfrac{1}{2} \cdot \dfrac{1}{1 - (1/2)} \\[2em]
      &= 1.
      \end{aligned}
    $$
  - It appears that our probability law is valid.
- Now consider calculating the probability that the outcome is even (that is, the number of tosses it took us to reach the first heads is even).
  $$
  \begin{aligned}
    P(\text{$n$ is even}) &= P(\set{2,4,6,\ldots}) \\[2em]
    &= P(\set{2} \cup \set{4} \cup \set{6} \cup \ldots) \\[2em]
    &= P(2) + P(4) + P(6) + \ldots \\[2em]
    &= \dfrac{1}{2^2} + \dfrac{1}{2^4} + \dfrac{1}{2^6} + \ldots \\[2em]
    &= \dfrac{1}{4} \left( 1 + \dfrac{1}{4} + \dfrac{1}{4^2} + \ldots \right) \\[2em]
    &= \dfrac{1}{4} \left( \dfrac{1}{1-(1/4)}\right) \\[2em]
    &= \dfrac{1}{3}.
  \end{aligned}
  $$
- That's an awfully nice rational number. Is our calculation correct? Yes, but only by luck. We made a mistake. Nothing that we've discussed so far allows us to take this step:
  $$
    P(\set{2} \cup \set{4} \cup \set{6} \cup \ldots)
    = P(2) + P(4) + P(6) + \ldots \\[2em]
  $$
- Our rule for summing disjoint sets only applies to _finitely many_ disjoint sets, not _infinitely many_. 
- We patch this issue with the _Countable Additivity Axiom_:
  - __*axiom*__. If ${A_1, A_2, A_3, \ldots}$ is an infinite sequence of disjoint events, then
    $$
      P(A_1 \cup A_2 \cup A_3 \cup \ldots) = P(A_1) + P(A_2) + P(A_3) + \ldots.
    $$  
    or, more concisely:
    $$
      P\left( \bigcup_{i = 0}^{\infty} A_i \right) = \sum_{i = 0}^{\infty} P(A_i).
    $$

import { L02_2, RadarExample } from "@/components/Fig";

## Conditional Probabilities
- Consider the following sample space for some experiment, comprising ${12}$ equally likely outcomes.
  <L02_2/>
- We see that ${P(A) = 5/12}$ and ${P(B) = 6/12.}$
- Suppose we're told that ${B}$ occurs. How does the model change?
  1. The outcomes outside of ${B}$ are no longer possible, so we assign them zero probability.
  2. There are six outcomes in ${B.}$ We stated that the outcomes are all equally likely, and we have not been given any reason to change the relative probabilities. So, these six outcomes remain equally likely. Thus, each outcome in ${B}$ now has a probability of ${1/6.}$
- We introduce some new notation for this situation:
  - ${P(A|B).}$ This means "the probability of ${A,}$ given that ${B}$ occurred." Here, we have two outcomes in ${A}$ and ${B,}$ each equally likely, so:
    $$
      P(A | B) = \dfrac{1}{6} + \dfrac{1}{6} = \dfrac{2}{6} = \dfrac{1}{3}.
    $$ 
  - ${P(B|B).}$ This means "the probability of ${B,}$ given that ${B}$ occurred." Since ${B}$ has occurred, we have:
    $$
      P(B | B) = 1.
    $$
- __*definition*__. The probability of ${A,}$ give that ${B}$ occurred, is given by:
  $$
    P(A | B) = \dfrac{P(A \cap B)}{P(B)}.
  $$
  provided that ${P(B) \gt 0.}$
- __*example*__. Consider a drone detection system. Suppose ${A}$ is the event where a drone is flying above. Suppose ${B}$ is the event where a red dot, indicating a drone, appears on the screen. Let's outline the possible scenarios:

<RadarExample/>

  - Here are what the set theoretic notations mean:
    1. ${A:}$ a drone is flying above.
    2. ${B:}$ red dot appears on the screen.
    3. ${A \cap B:}$ a drone is flying above _and_ a red dot appears on the screen.
    4. ${A \cap B^c:}$ a drone is flying above and a red dot _does not_ appear on the screen (a _false negative_).
    5. ${A^c \cap B:}$ a drone is _not_ flying above and a red dot appears on the screen (a _false positive_).
    6. ${A^c \cap B^c:}$ a drone is _not_ flying above and a red dot _does not_ appear on the screen. 
  - Let's say, through repeated testing of the drone detection system, we find that: 
    - ${P(A) = 0.05.}$
    - ${P(A^c) = 0.95.}$ 
  - We annotate these probabilities along the tree's edges above.
  - What do the other probabilities mean?
    - ${0.99}$ corresponds to the probability of ${B}$ (a red dot appearing on the screen) given ${A}$ (a drone flying). I.e., ${P(B | A) = 0.99.}$
    - ${0.01}$ corresponds to the probability of _not_ ${B}$ (a red dot _not_ appearing on the screen) given ${A}$ (no drone is flying above). I.e., ${P(B^c | A).}$ 
    - Similarly, ${P(B | A^c) = 0.1}$ (the probability of a red dot appearing given _no_ drone flying above is ${0.1}$).
    - And ${P(A^c | B^c) = 0.9}$ (the probability of a red dot _not_ appearing given _no_ drone is flying above is ${0.9}$). 
- __*example.*__ Let's calculate some probabilities.
  1. The probability of a drone flying overhead and the system detecting it: 
    $$
      \begin{aligned}
        P(A \cap B) &= P(A) \cdot P(B) \\ 
        &= 0.05 \cdot 0.99 \\
        &= 0.0495.
      \end{aligned}
    $$
  2. The probability of ${B:}$
    $$
      \begin{aligned}
        P(B) &= (0.05 \cdot 0.99) + (0.95 \cdot 0.1) \\
        &= 0.1445.
      \end{aligned}
    $$
  3. The probability of a drone flying overhead given the system has detected it.
    $$
      \begin{aligned}
        P(A | B) &= \dfrac{0.05 \cdot 0.99}{0.95 \cdot 0.1} \\[2em]
        &= 0.34.
      \end{aligned}
    $$
    This example is interesting. It tells us that, despite such an accurate system, the fact that it detects a drone does not imply that there is a drone. 

### Multiplication Rule
- Consider:
  $$
    P(A ~|~ B) = \dfrac{P(A \cap B)}{P(B)}.
  $$ 
  Rearranging:
  $$
    \begin{aligned}
      P(A \cap B) &= P(B) \cdot P(A ~|~ B) \\
      &= P(A) \cdot P(B ~|~ A).
    \end{aligned}
  $$
- This is a simple application of the _multiplication rule of probabilities_.
  - __*multiplication rule*__. 
    $$
      P(A_1 \cap A_2 \cap \ldots \cap A_n) = P(A_1) \prod_{i=2}^{n} P(A_i ~|~ A_1 \cap A_2 \cap \ldots \cap A_{i-1}).
    $$ 

import { PartitionedSampleSpace } from "@/components/Fig";

## Total Probability Theorem
- Say we have the following sample space, partitioned into ${A_1,}$ ${A_2,}$ and ${A_3.}$
  <PartitionedSampleSpace/>
- The event ${B}$ can happen in three different ways:
  1. ${B}$ given ${A_1}$ occurred (${A_3 \cap B}$).
  2. ${B}$ given ${A_2}$ occurred (${A_2 \cap B}$).
  3. ${B}$ given ${A_3}$ occurred (${A_3 \cap B}$).
- Can we compute ${P(B)}$? Yes:
  $$
    \begin{aligned}
      P(B) &= P(B \cap A_1) + P(B \cap A_2) + P(B \cap A_3) \\ 
      &= P(A_1) \cdot P(B ~|~ A_1) + P(A_2) \cdot P(B ~|~ A_2) + \ldots + \ldots
    \end{aligned}
  $$  
- This leads to the following formula:
  $$
    P(B) = \sum_{i=1}^{n} P(A_i) P(B ~|~ A_i).
  $$ 
  - Notice that ${P(B)}$ looks like a _weighted average_ of ${P(B ~|~ A_i),}$ where the weight is ${P(A_i).}$ 

## Bayes's Rule
- Bayes's Rule is a systematic approach for incorporating new evidence. 
- Imagine a sample space partitioned in three tripartites: ${A_1,}$ ${A_2,}$ and ${A_3.}$ We call each tripartite a _scenario_.
- Now let's say we assign each scenario a probability (based on some method; perhaps repeated experimentation, inferences from other experiments, etc.) Thus, we have ${P(A_i)}$ for every ${i.}$ We call these initial probabilities our _initial beliefs_. 
- Under each scenario, we have an event ${B.}$ Each event ${B}$ under ${A_i}$ has a probability that it will occur given the scenario ${A_i.}$ Thus, we have ${P(B ~|~ A_i)}$ for every ${i.}$
- Now the experiment is carried out, and we observe that ${B}$ does occur. 
- The moment this happens, we ought to revise our beliefs about the likelihoods of  the different scenarios, ${A_i.}$ Perhaps, because of ${B}$'s occurrence, other events become suddenly more likely.
- We revise our beliefs by calculating conditional probabilities.

## Independence
- __*definition*__. Events ${A}$ and ${B}$ are independent if and only if
  $$
    P(A \cap B) = P(A) \cdot P(B).
  $$ 
- In other words, events ${A}$ and ${B}$ are independent if the occurrence of ${A}$ has no effect on the probability of ${B}$'s occurrence.



export default function MDXPage({ children }) {
  return <MdxLayout>{children}</MdxLayout>;
}